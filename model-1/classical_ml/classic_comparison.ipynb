{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test CSV\n",
    "test_csv_path = r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\test_set4.csv\"\n",
    "df = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text.lower())\n",
    "    # Remove punctuation and non-alphabetic tokens\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column names\n",
    "text_column = \"text\"  # Column containing the text data\n",
    "true_labels_column = \"Classification\"  # Column containing the true labels\n",
    "\n",
    "# Define multiple model and vectorizer paths\n",
    "model_paths = [\n",
    "    r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\ridge_classifier_model.pkl\",\n",
    "    r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\ridge_classifier_model_5k.pkl\",\n",
    "    r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\best_xgb_model.pkl\",\n",
    "]\n",
    "\n",
    "vectorizer_paths = [\n",
    "    r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\vectorizer_final.pkl\",\n",
    "    r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\vectorizer_5k.pkl\",\n",
    "    r\"C:\\Users\\user\\OneDrive - National University of Singapore\\Desktop\\Y4S1\\DSA4264\\DSA4264-Detoxify\\model-1\\classical_ml\\vectorizer_final.pkl\",\n",
    "]\n",
    "\n",
    "# Class labels (ensure these match the numerical labels in your true_labels_column)\n",
    "label_mapping = {\n",
    "    0: \"No Hate/Toxic\",\n",
    "    1: \"Toxic 1\",\n",
    "    2: \"Toxic 2\",\n",
    "    3: \"Toxic 3\",\n",
    "    4: \"Hate 1\",\n",
    "    5: \"Hate 2\",\n",
    "    6: \"Hate 3\",\n",
    "}\n",
    "\n",
    "# Reverse mapping for predictions\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 15750/15750 [00:04<00:00, 3833.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model 1...\n",
      "Model 1 and vectorizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with Model 1: 15750sample [00:01, 8817.91sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Model 1:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.62      0.74      0.67      2250\n",
      "      Toxic 1       0.54      0.60      0.57      2250\n",
      "      Toxic 2       0.90      0.69      0.78      2250\n",
      "      Toxic 3       1.00      0.98      0.99      2250\n",
      "       Hate 1       0.73      0.75      0.74      2250\n",
      "       Hate 2       0.99      0.94      0.97      2250\n",
      "       Hate 3       1.00      0.98      0.99      2250\n",
      "\n",
      "     accuracy                           0.81     15750\n",
      "    macro avg       0.83      0.81      0.81     15750\n",
      " weighted avg       0.83      0.81      0.81     15750\n",
      "\n",
      "\n",
      "Evaluating Model 2...\n",
      "Model 2 and vectorizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with Model 2: 15750sample [00:01, 9063.97sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Model 2:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.53      0.70      0.61      2250\n",
      "      Toxic 1       0.46      0.42      0.44      2250\n",
      "      Toxic 2       0.41      0.33      0.36      2250\n",
      "      Toxic 3       0.95      0.98      0.97      2250\n",
      "       Hate 1       0.72      0.72      0.72      2250\n",
      "       Hate 2       0.99      0.94      0.96      2250\n",
      "       Hate 3       0.99      0.99      0.99      2250\n",
      "\n",
      "     accuracy                           0.72     15750\n",
      "    macro avg       0.72      0.72      0.72     15750\n",
      " weighted avg       0.72      0.72      0.72     15750\n",
      "\n",
      "\n",
      "Evaluating Model 3...\n",
      "Model 3 and vectorizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with Model 3: 15750sample [00:09, 1595.30sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Model 3:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.55      0.77      0.65      2250\n",
      "      Toxic 1       0.53      0.54      0.54      2250\n",
      "      Toxic 2       0.89      0.67      0.77      2250\n",
      "      Toxic 3       0.99      0.98      0.98      2250\n",
      "       Hate 1       0.77      0.69      0.73      2250\n",
      "       Hate 2       0.99      0.94      0.96      2250\n",
      "       Hate 3       1.00      0.98      0.99      2250\n",
      "\n",
      "     accuracy                           0.80     15750\n",
      "    macro avg       0.82      0.80      0.80     15750\n",
      " weighted avg       0.82      0.80      0.80     15750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract text data and preprocess with progress bar\n",
    "texts = df[text_column].tolist()\n",
    "processed_samples = [preprocess(text) for text in tqdm(texts, desc=\"Preprocessing\")]\n",
    "\n",
    "# Predict with each model and vectorizer\n",
    "for i, (model_path, vectorizer_path) in enumerate(\n",
    "    zip(model_paths, vectorizer_paths), start=1\n",
    "):\n",
    "    print(f\"\\nEvaluating Model {i}...\")\n",
    "\n",
    "    # Load the model and vectorizer\n",
    "    clf = joblib.load(model_path)\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    print(f\"Model {i} and vectorizer loaded successfully.\")\n",
    "\n",
    "    # Vectorize the input\n",
    "    new_input_vectorized = vectorizer.transform(processed_samples)\n",
    "\n",
    "    # Predict using the loaded model with progress bar\n",
    "    predictions = []\n",
    "    for vec_sample in tqdm(\n",
    "        new_input_vectorized, desc=f\"Predicting with Model {i}\", unit=\"sample\"\n",
    "    ):\n",
    "        pred = clf.predict(vec_sample)  # Predict each sample individually\n",
    "        predictions.append(pred[0])  # Append the prediction result\n",
    "\n",
    "    # Convert predicted labels to match the format of true labels\n",
    "    predicted_labels = [\n",
    "        reverse_label_mapping[label_mapping[pred]] for pred in predictions\n",
    "    ]\n",
    "\n",
    "    # Store predictions in DataFrame\n",
    "    df[f\"predicted_labels_model_{i}\"] = predicted_labels\n",
    "\n",
    "    # Generate and print classification report\n",
    "    print(f\"\\nClassification Report for Model {i}:\\n\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            df[true_labels_column],\n",
    "            df[f\"predicted_labels_model_{i}\"],\n",
    "            target_names=list(label_mapping.values()),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
