{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load on GPU\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the given CSV file into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(filepath, engine=\"python\")\n",
    "        print(f\"Data successfully loaded from {filepath}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading the CSV file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from C:\\Users\\E.Sin\\Desktop\\Richmond\\DSA4264-Detoxify\\model-1\\bert\\final_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>username</th>\n",
       "      <th>link</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>moderation</th>\n",
       "      <th>year</th>\n",
       "      <th>concatenated_count</th>\n",
       "      <th>complete_thread</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>generated_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id of j3qufpv said this: Whipping, spanking, s...</td>\n",
       "      <td>1/10/2023 13:21</td>\n",
       "      <td>jypt98</td>\n",
       "      <td>/r/SingaporeRaw/comments/10870bh/how_on_earth_...</td>\n",
       "      <td>t3_10870bh</td>\n",
       "      <td>t1_j3qj0kb</td>\n",
       "      <td>j3qufpv</td>\n",
       "      <td>t5_xnx04</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Toxic 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id of j2m21l2 said this: Some more they just p...</td>\n",
       "      <td>1/2/2023 9:05</td>\n",
       "      <td>killthebutter</td>\n",
       "      <td>/r/singapore/comments/10146t7/true_sentiment_a...</td>\n",
       "      <td>t3_10146t7</td>\n",
       "      <td>t1_j2m1ttf</td>\n",
       "      <td>j2m21l2</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Toxic 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is hard to believe that this person thinks ...</td>\n",
       "      <td>10/22/2023 03:47:29 AM</td>\n",
       "      <td>rpnrml</td>\n",
       "      <td>/r/singapore/comments/13c3mt8/Strict_appearanc...</td>\n",
       "      <td>t3_7iylmyx</td>\n",
       "      <td>t3_7iylmyx</td>\n",
       "      <td>but9he5</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic 1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If those LGBTQ+ people don't leave, they'll re...</td>\n",
       "      <td>03/25/2023 11:40:46 PM</td>\n",
       "      <td>rhfgdq</td>\n",
       "      <td>/r/singapore/comments/13c3mt8/Strict_appearanc...</td>\n",
       "      <td>t3_37dlf9l</td>\n",
       "      <td>t3_37dlf9l</td>\n",
       "      <td>ujw1rw5</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hate 3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id of j4ydf6r said this: Its funny how you mad...</td>\n",
       "      <td>1/19/2023 2:55</td>\n",
       "      <td>laglory</td>\n",
       "      <td>/r/SingaporeRaw/comments/10foele/should_we_tes...</td>\n",
       "      <td>t3_10foele</td>\n",
       "      <td>t1_j4yasmb</td>\n",
       "      <td>j4ydf6r</td>\n",
       "      <td>t5_xnx04</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Toxic 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>These immigrants need to stop stealing from us...</td>\n",
       "      <td>07/27/2023 09:18:11 AM</td>\n",
       "      <td>cwycse</td>\n",
       "      <td>/r/singapore/comments/13c3mt8/Strict_appearanc...</td>\n",
       "      <td>t3_2q1fpxz</td>\n",
       "      <td>t3_2q1fpxz</td>\n",
       "      <td>y0gselo</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hate 3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>id of j4u2utd said this: Keeps people employed.</td>\n",
       "      <td>1/18/2023 6:44</td>\n",
       "      <td>throwabaysands</td>\n",
       "      <td>/r/SingaporeRaw/comments/10esyre/average_perso...</td>\n",
       "      <td>t3_10esyre</td>\n",
       "      <td>t1_j4u1w2c</td>\n",
       "      <td>j4u2utd</td>\n",
       "      <td>t5_xnx04</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No Hate/Toxic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>id of j3jl3hr said this: This is kids why you ...</td>\n",
       "      <td>1/9/2023 0:38</td>\n",
       "      <td>cd-t</td>\n",
       "      <td>/r/singapore/comments/106l2l7/kia_amp_mercedes...</td>\n",
       "      <td>t3_106l2l7</td>\n",
       "      <td>t3_106l2l7</td>\n",
       "      <td>j3jl3hr</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Toxic 2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>id of j4m2xid said this: I don't understand wh...</td>\n",
       "      <td>1/16/2023 18:03</td>\n",
       "      <td>gamerx88</td>\n",
       "      <td>/r/singapore/comments/10djalo/jeanne_tens_long...</td>\n",
       "      <td>t3_10djalo</td>\n",
       "      <td>t3_10djalo</td>\n",
       "      <td>j4m2xid</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 1, 'collapsed_reason_code...</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No Hate/Toxic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>“People from wealthy backgrounds don’t underst...</td>\n",
       "      <td>10/04/2021 03:27:46 PM</td>\n",
       "      <td>szidnv</td>\n",
       "      <td>/r/singapore/comments/13c3mt8/riduculous_peopl...</td>\n",
       "      <td>t3_ewtq4sw</td>\n",
       "      <td>t3_ewtq4sw</td>\n",
       "      <td>0zum5hc</td>\n",
       "      <td>t5_2qh8c</td>\n",
       "      <td>{'controversiality': 0, 'collapsed_reason_code...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hate 1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      id of j3qufpv said this: Whipping, spanking, s...   \n",
       "1      id of j2m21l2 said this: Some more they just p...   \n",
       "2      It is hard to believe that this person thinks ...   \n",
       "3      If those LGBTQ+ people don't leave, they'll re...   \n",
       "4      id of j4ydf6r said this: Its funny how you mad...   \n",
       "...                                                  ...   \n",
       "69995  These immigrants need to stop stealing from us...   \n",
       "69996    id of j4u2utd said this: Keeps people employed.   \n",
       "69997  id of j3jl3hr said this: This is kids why you ...   \n",
       "69998  id of j4m2xid said this: I don't understand wh...   \n",
       "69999  “People from wealthy backgrounds don’t underst...   \n",
       "\n",
       "                    timestamp        username  \\\n",
       "0             1/10/2023 13:21          jypt98   \n",
       "1               1/2/2023 9:05   killthebutter   \n",
       "2      10/22/2023 03:47:29 AM          rpnrml   \n",
       "3      03/25/2023 11:40:46 PM          rhfgdq   \n",
       "4              1/19/2023 2:55         laglory   \n",
       "...                       ...             ...   \n",
       "69995  07/27/2023 09:18:11 AM          cwycse   \n",
       "69996          1/18/2023 6:44  throwabaysands   \n",
       "69997           1/9/2023 0:38            cd-t   \n",
       "69998         1/16/2023 18:03        gamerx88   \n",
       "69999  10/04/2021 03:27:46 PM          szidnv   \n",
       "\n",
       "                                                    link     link_id  \\\n",
       "0      /r/SingaporeRaw/comments/10870bh/how_on_earth_...  t3_10870bh   \n",
       "1      /r/singapore/comments/10146t7/true_sentiment_a...  t3_10146t7   \n",
       "2      /r/singapore/comments/13c3mt8/Strict_appearanc...  t3_7iylmyx   \n",
       "3      /r/singapore/comments/13c3mt8/Strict_appearanc...  t3_37dlf9l   \n",
       "4      /r/SingaporeRaw/comments/10foele/should_we_tes...  t3_10foele   \n",
       "...                                                  ...         ...   \n",
       "69995  /r/singapore/comments/13c3mt8/Strict_appearanc...  t3_2q1fpxz   \n",
       "69996  /r/SingaporeRaw/comments/10esyre/average_perso...  t3_10esyre   \n",
       "69997  /r/singapore/comments/106l2l7/kia_amp_mercedes...  t3_106l2l7   \n",
       "69998  /r/singapore/comments/10djalo/jeanne_tens_long...  t3_10djalo   \n",
       "69999  /r/singapore/comments/13c3mt8/riduculous_peopl...  t3_ewtq4sw   \n",
       "\n",
       "        parent_id       id subreddit_id  \\\n",
       "0      t1_j3qj0kb  j3qufpv     t5_xnx04   \n",
       "1      t1_j2m1ttf  j2m21l2     t5_2qh8c   \n",
       "2      t3_7iylmyx  but9he5     t5_2qh8c   \n",
       "3      t3_37dlf9l  ujw1rw5     t5_2qh8c   \n",
       "4      t1_j4yasmb  j4ydf6r     t5_xnx04   \n",
       "...           ...      ...          ...   \n",
       "69995  t3_2q1fpxz  y0gselo     t5_2qh8c   \n",
       "69996  t1_j4u1w2c  j4u2utd     t5_xnx04   \n",
       "69997  t3_106l2l7  j3jl3hr     t5_2qh8c   \n",
       "69998  t3_10djalo  j4m2xid     t5_2qh8c   \n",
       "69999  t3_ewtq4sw  0zum5hc     t5_2qh8c   \n",
       "\n",
       "                                              moderation  year  \\\n",
       "0      {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "1      {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "2      {'controversiality': 0, 'collapsed_reason_code...  2021   \n",
       "3      {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "4      {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "...                                                  ...   ...   \n",
       "69995  {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "69996  {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "69997  {'controversiality': 0, 'collapsed_reason_code...  2023   \n",
       "69998  {'controversiality': 1, 'collapsed_reason_code...  2023   \n",
       "69999  {'controversiality': 0, 'collapsed_reason_code...  2021   \n",
       "\n",
       "       concatenated_count  complete_thread     gold_label  generated_data  \n",
       "0                       1                0        Toxic 1           False  \n",
       "1                       1                0        Toxic 1           False  \n",
       "2                       1                1        Toxic 1            True  \n",
       "3                       1                1         Hate 3            True  \n",
       "4                       1                0        Toxic 1           False  \n",
       "...                   ...              ...            ...             ...  \n",
       "69995                   1                1         Hate 3            True  \n",
       "69996                   1                0  No Hate/Toxic           False  \n",
       "69997                   1                1        Toxic 2           False  \n",
       "69998                   2                1  No Hate/Toxic           False  \n",
       "69999                   1                1         Hate 1            True  \n",
       "\n",
       "[70000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_csv(\n",
    "    r\"C:\\Users\\E.Sin\\Desktop\\Richmond\\DSA4264-Detoxify\\model-1\\bert\\final_data.csv\"\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for model training.\n",
    "MAX_LEN = 200\n",
    "num_classes = 7\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "TEST_BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update class-to-id mapping for 7 classes\n",
    "cls_to_id = {\n",
    "    \"No Hate/Toxic\": 0,\n",
    "    \"Hate 1\": 1,\n",
    "    \"Hate 2\": 2,\n",
    "    \"Hate 3\": 3,\n",
    "    \"Toxic 1\": 4,\n",
    "    \"Toxic 2\": 5,\n",
    "    \"Toxic 3\": 6,\n",
    "}\n",
    "\n",
    "id_to_cls = {v: k for k, v in cls_to_id.items()}\n",
    "\n",
    "num_classes = 7  # Update the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 49000\n",
      "Validation set size: 10500\n",
      "Test set size: 10500\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to integer format\n",
    "data[\"gold_label\"] = data[\"gold_label\"].map(cls_to_id)\n",
    "data = data.dropna(subset=[\"gold_label\"])\n",
    "data[\"gold_label\"] = data[\"gold_label\"].astype(int)\n",
    "\n",
    "# Step 1: Split the data into 70% train and 30% (validation + test)\n",
    "df_train, df_temp = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,  # 30% for validation and test\n",
    "    shuffle=True,  # Shuffle only during the first split\n",
    "    stratify=data[\"gold_label\"],  # Maintain class distribution\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Step 2: Split the remaining 30% into 15% validation and 15% test\n",
    "# NOTE: Now stratifying using the labels from df_temp, not data\n",
    "df_valid, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,  # Split 50-50 between validation and test from the remaining 30%\n",
    "    shuffle=True,\n",
    "    stratify=df_temp[\"gold_label\"],  # Correct stratification\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Display the sizes of each set\n",
    "print(f\"Training set size: {len(df_train)}\")\n",
    "print(f\"Validation set size: {len(df_valid)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = df[\"text\"].values\n",
    "        self.targets = df[\"gold_label\"].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        text = \" \".join(text.split())  # Clean text\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].flatten(),\n",
    "            \"token_type_ids\": inputs[\"token_type_ids\"].flatten(),\n",
    "            \"targets\": torch.tensor(self.targets[index], dtype=torch.long),\n",
    "            \"text\": text,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7000 7000 7000 7000 7000 7000 7000]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have 10,000 samples per class and 7 classes\n",
    "num_samples = len(df_train)\n",
    "num_classes = len(np.unique(df_train[\"gold_label\"]))\n",
    "class_counts = np.bincount(df_train[\"gold_label\"])\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00014286 0.00014286 0.00014286 ... 0.00014286 0.00014286 0.00014286]\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights (inverse of class frequency)\n",
    "class_weights = 1.0 / class_counts\n",
    "sample_weights = class_weights[df_train[\"gold_label\"]]\n",
    "print(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 49000\n",
      "Validation dataset size: 10500\n",
      "Test dataset size: 10500\n",
      "Number of batches in training DataLoader: 12250\n",
      "Number of batches in validation DataLoader: 2625\n",
      "Number of batches in test DataLoader: 2625\n"
     ]
    }
   ],
   "source": [
    "# Create WeightedRandomSampler for balanced class sampling for the training dataset\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,  # You need to define how to calculate these sample weights\n",
    "    num_samples=num_samples,\n",
    "    replacement=False,\n",
    ")\n",
    "\n",
    "# Create datasets for train, validation, and test sets\n",
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)  # Add the test dataset\n",
    "\n",
    "# Data loaders\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,  # Use the weighted sampler here\n",
    "    num_workers=4,  # Increase num_workers for faster loading\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,  # No need to shuffle validation data\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,  # Typically use the same batch size as validation\n",
    "    shuffle=False,  # No need to shuffle test data\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "# Check the length of the datasets\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")  # Check the size of the test dataset\n",
    "\n",
    "# Check the number of batches in the DataLoader\n",
    "print(f\"Number of batches in training DataLoader: {len(train_data_loader)}\")\n",
    "print(f\"Number of batches in validation DataLoader: {len(val_data_loader)}\")\n",
    "print(\n",
    "    f\"Number of batches in test DataLoader: {len(test_data_loader)}\"\n",
    ")  # Check the number of batches for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(\n",
    "            \"bert-base-uncased\", return_dict=True\n",
    "        )\n",
    "\n",
    "        # Additional fully connected and dropout layers\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "        # Final output layer for classification\n",
    "        self.linear = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, attention_mask=attn_mask, token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        x = self.fc1(output.pooler_output)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights based on the balanced data\n",
    "class_counts = data[\"gold_label\"].value_counts().sort_index()\n",
    "class_weights = 1.0 / class_counts  # Inverse of class frequency\n",
    "class_weights = class_weights / class_weights.sum()  # Normalize the weights\n",
    "\n",
    "# Convert to a tensor and move to the correct device (GPU)\n",
    "class_weights_tensor = torch.tensor(class_weights.values, dtype=torch.float).to(device)\n",
    "\n",
    "# Use class weights in CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/12250 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = BERTClass(num_classes=num_classes)\n",
    "\n",
    "# Move the model to the appropriate device (use all available GPUs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function (already set with class weights) and optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    # Create a progress bar for the training data loader\n",
    "    train_loader_tqdm = tqdm(\n",
    "        train_data_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", unit=\"batch\"\n",
    "    )\n",
    "\n",
    "    # Training step with progress bar\n",
    "    for batch in train_loader_tqdm:\n",
    "        ids = batch[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        labels = batch[\"targets\"].to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(ids, mask, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "        # Collect labels and predictions for precision, recall, and F1 calculation\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        # Update the progress bar with loss\n",
    "        train_loader_tqdm.set_postfix(\n",
    "            {\"train_loss\": total_loss / (train_loader_tqdm.n + 1)}\n",
    "        )\n",
    "\n",
    "    # Calculate average loss and accuracy for this epoch\n",
    "    avg_loss = total_loss / len(train_data_loader)\n",
    "    accuracy = correct_predictions / len(train_data_loader.dataset)\n",
    "\n",
    "    # Calculate precision, recall, and F1 for training\n",
    "    precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    # Record the end time and calculate duration\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time  # Time taken for this epoch\n",
    "\n",
    "    print(f\"Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}\")\n",
    "    print(\n",
    "        f\"Train Precision: {precision:.4f}, Train Recall: {recall:.4f}, Train F1-Score: {f1:.4f}\"\n",
    "    )\n",
    "    print(f\"Epoch Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "    # Validation step with progress bar\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    # Create a progress bar for the validation data loader\n",
    "    val_loader_tqdm = tqdm(val_data_loader, desc=\"Validating\", unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader_tqdm:\n",
    "            ids = batch[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            labels = batch[\"targets\"].to(device, dtype=torch.long)\n",
    "\n",
    "            logits = model(ids, mask, token_type_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            val_correct += torch.sum(preds == labels).item()\n",
    "\n",
    "            # Collect validation labels and predictions for metrics\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            # Update the progress bar with validation loss\n",
    "            val_loader_tqdm.set_postfix(\n",
    "                {\"val_loss\": val_loss / (val_loader_tqdm.n + 1)}\n",
    "            )\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_data_loader)\n",
    "    val_accuracy = val_correct / len(val_data_loader.dataset)\n",
    "\n",
    "    # Calculate precision, recall, and F1 for validation\n",
    "    val_precision = precision_score(val_labels, val_preds, average=\"weighted\")\n",
    "    val_recall = recall_score(val_labels, val_preds, average=\"weighted\")\n",
    "    val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n",
    "\n",
    "    print(\n",
    "        f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1-Score: {val_f1:.4f}\"\n",
    "    )\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_number = 4\n",
    "\n",
    "# Save the trained model weights\n",
    "model_save_path = f\"bert_model_{training_number}.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Initialize the model architecture (exactly the same as when the model was trained)\n",
    "model = BERTClass(num_classes=num_classes)\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the saved model weights onto the correct device\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a validation DataLoader\n",
    "\n",
    "\n",
    "def get_predictions_and_labels(model, data_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    texts = []\n",
    "    probabilities = []\n",
    "\n",
    "    # Wrap the data loader with tqdm to create a progress bar\n",
    "    loader_tqdm = tqdm(data_loader, desc=\"Generating predictions\", unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader_tqdm:  # Use tqdm wrapped data_loader\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            labels = batch[\"targets\"].to(device)\n",
    "            text_batch = batch[\"text\"]  # Collecting texts\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            probs = nn.functional.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            texts.extend(text_batch)  # Collect texts\n",
    "            probabilities.extend(probs.cpu().numpy())  # Store probabilities\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels), texts, np.array(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and labels for the test set\n",
    "predictions, true_labels, texts, probabilities = get_predictions_and_labels(\n",
    "    model, test_data_loader, device\n",
    ")\n",
    "# Extract class names from id_to_cls mapping\n",
    "class_names = [id_to_cls[i] for i in range(num_classes)]\n",
    "print(classification_report(true_labels, predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate class-wise accuracy with tqdm\n",
    "\n",
    "\n",
    "def calculate_class_wise_accuracy(conf_matrix):\n",
    "    # True Positives for each class are the diagonal elements\n",
    "    true_positives = np.diag(conf_matrix)\n",
    "\n",
    "    # Support (Total actual instances for each class)\n",
    "    support = conf_matrix.sum(axis=1)\n",
    "\n",
    "    # Initialize list to store class-wise accuracy\n",
    "    class_wise_accuracy = []\n",
    "\n",
    "    # Use tqdm to show progress while calculating accuracy for each class\n",
    "    for i in tqdm(\n",
    "        range(len(true_positives)), desc=\"Calculating class-wise accuracy\", unit=\"class\"\n",
    "    ):\n",
    "        if support[i] != 0:  # Avoid division by zero\n",
    "            accuracy = true_positives[i] / support[i]\n",
    "        else:\n",
    "            accuracy = 0.0\n",
    "        class_wise_accuracy.append(accuracy)\n",
    "\n",
    "    return np.array(class_wise_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get misclassified samples with tqdm\n",
    "\n",
    "\n",
    "def get_misclassified_samples(predictions, true_labels, texts):\n",
    "    misclassified = []\n",
    "\n",
    "    # Wrap the iteration with tqdm for a progress bar\n",
    "    for pred, true, text in tqdm(\n",
    "        zip(predictions, true_labels, texts),\n",
    "        desc=\"Finding misclassified samples\",\n",
    "        total=len(predictions),\n",
    "        unit=\"sample\",\n",
    "    ):\n",
    "        if pred != true:\n",
    "            misclassified.append(\n",
    "                {\"text\": text, \"true_label\": true, \"predicted_label\": pred}\n",
    "            )\n",
    "\n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# Calculate precision, recall, and F1-score (with zero_division handling)\n",
    "precision = precision_score(\n",
    "    true_labels, predictions, average=\"weighted\", zero_division=0\n",
    ")\n",
    "recall = recall_score(true_labels, predictions, average=\"weighted\", zero_division=0)\n",
    "f1 = f1_score(true_labels, predictions, average=\"weighted\", zero_division=0)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# Normalize confusion matrix\n",
    "conf_matrix_normalized = (\n",
    "    conf_matrix.astype(\"float\") / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    ")\n",
    "\n",
    "# Set plot size and style\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(font_scale=1.2)  # Adjust font size\n",
    "\n",
    "# Plot normalized confusion matrix with percentage formatting\n",
    "ax = sns.heatmap(\n",
    "    conf_matrix_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2%\",\n",
    "    cmap=\"coolwarm\",\n",
    "    xticklabels=list(cls_to_id.keys()),\n",
    "    yticklabels=list(cls_to_id.keys()),\n",
    ")\n",
    "\n",
    "# Ensure equal aspect ratio for x and y axes\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Improve plot aesthetics\n",
    "ax.set_xlabel(\"Predicted Labels\", fontsize=14)\n",
    "ax.set_ylabel(\"True Labels\", fontsize=14)\n",
    "ax.set_title(\"Normalized Confusion Matrix\", fontsize=16)\n",
    "\n",
    "# Adjust tick positions and spread them outwards\n",
    "ax.xaxis.set_ticks_position(\"top\")  # Move x-axis ticks to the top\n",
    "ax.xaxis.set_label_position(\"top\")  # Move x-axis label to the top\n",
    "\n",
    "# Set xticks and yticks to center-align with matrix cells\n",
    "ax.set_xticks([i + 0.5 for i in range(len(cls_to_id))])\n",
    "ax.set_yticks([i + 0.5 for i in range(len(cls_to_id))])\n",
    "\n",
    "# Apply label rotation to improve readability (optional)\n",
    "plt.xticks(rotation=45, ha=\"center\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig(\"normalized_confusion_matrix.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get misclassified samples\n",
    "misclassified_samples = get_misclassified_samples(predictions, true_labels, texts)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "misclassified_df = pd.DataFrame(misclassified_samples)\n",
    "\n",
    "misclassified_df[\"true_label\"] = misclassified_df[\"true_label\"].apply(\n",
    "    lambda x: id_to_cls[x]\n",
    ")\n",
    "misclassified_df[\"predicted_label\"] = misclassified_df[\"predicted_label\"].apply(\n",
    "    lambda x: id_to_cls[x]\n",
    ")\n",
    "\n",
    "# Display misclassified samples\n",
    "print(misclassified_df.shape, len(predictions))\n",
    "# misclassified_df.to_csv('./data/misclassified_df.csv', index=False)\n",
    "misclassified_df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
