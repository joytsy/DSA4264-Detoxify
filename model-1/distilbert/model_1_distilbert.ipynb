{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    DistilBertConfig,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = df[\"text\"].values\n",
    "        self.targets = df[\"gold_label\"].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        target = self.targets[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"targets\": torch.tensor(target, dtype=torch.long),  # Ensure correct dtype\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert String Labels to Integers\n",
    "label_mapping = {\n",
    "    \"No Hate/Toxic\": 0,\n",
    "    \"Toxic 1\": 1,\n",
    "    \"Toxic 2\": 2,\n",
    "    \"Toxic 3\": 3,\n",
    "    \"Hate 1\": 4,\n",
    "    \"Hate 2\": 5,\n",
    "    \"Hate 3\": 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map string labels to integers\n",
    "df[\"gold_label\"] = df[\"gold_label\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified train-test split to maintain class balance\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df[\"gold_label\"]\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"gold_label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 7  # For multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "# Set dropout rates and number of labels\n",
    "config.attention_probs_dropout_prob = 0.2  # Increase dropout rate\n",
    "config.hidden_dropout_prob = 0.2  # Increase dropout rate\n",
    "config.num_labels = 7  # Number of output classes\n",
    "\n",
    "# Initialize the model with the modified configuration\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-multilingual-cased\", config=config\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the model\n",
    "save_path = (\n",
    "    r\"C:\\Users\\richm\\OneDrive\\Desktop\\DSA4264\\DSA4264-Detoxify\\model-1\\distilbert\"\n",
    ")\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of training steps\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Define warmup steps (e.g., 10% of total steps)\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "# Scheduler with warmup for the first X steps, then linear decay\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training and Evaluation Functions with tqdm\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Wrap data_loader with tqdm to show progress\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Add scheduler step here\n",
    "\n",
    "        # Update progress bar description with running metrics\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": total_loss / (total_samples / BATCH_SIZE),\n",
    "                \"accuracy\": correct_predictions.double() / total_samples,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    return total_loss / len(data_loader), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [label for label, _ in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Wrap data_loader with tqdm to show progress during evaluation\n",
    "    progress_bar = tqdm(data_loader, desc=\"Validating\", unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "            # Update progress bar description with running metrics\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": total_loss / (total_samples / BATCH_SIZE),\n",
    "                    \"accuracy\": correct_predictions.double() / total_samples,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    # Print classification report to get precision, recall, and F1 per class\n",
    "    class_report = classification_report(\n",
    "        all_labels, all_preds, target_names=class_names\n",
    "    )\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy.item(), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variable to track the best validation loss\n",
    "best_val_loss = float(\"inf\")  # Start with a very high value\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # Pass the scheduler to train_epoch\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, optimizer, criterion, device, scheduler\n",
    "    )\n",
    "    print(f\"Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    val_loss, val_acc, val_f1 = eval_model(model, val_loader, criterion, device)\n",
    "    print(\n",
    "        f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}, Validation F1: {val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check if the current validation loss is better than the best we've seen\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss  # Update the best validation loss\n",
    "        best_model = model.state_dict()  # Save the current model state\n",
    "\n",
    "# Save the best model after training\n",
    "model_save_path = os.path.join(save_path, \"best_distilbert_model.pth\")\n",
    "torch.save(best_model, model_save_path)\n",
    "print(\n",
    "    f\"Best model saved at {model_save_path} with validation loss: {best_val_loss:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model after training\n",
    "model_save_path = os.path.join(save_path, \"distilbert_model.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Final model saved at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Evaluate the Model on Test Set\n",
    "# Print the size of the test dataset\n",
    "test_data_size = len(test_loader.dataset)\n",
    "print(f\"Exact length of test data: {test_data_size}\\n\")  # Added new line for clarity\n",
    "\n",
    "# Evaluate the model on the test set and print metrics\n",
    "test_loss, test_acc, test_f1 = eval_model(model, test_loader, criterion, device)\n",
    "print(\n",
    "    f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
