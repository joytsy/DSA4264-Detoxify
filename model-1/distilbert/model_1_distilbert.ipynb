{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    DistilBertConfig,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = df[\"text\"].values\n",
    "        self.targets = df[\"Classification\"].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        target = self.targets[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"targets\": torch.tensor(target, dtype=torch.long),  # Ensure correct dtype\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert String Labels to Integers\n",
    "label_mapping = {\n",
    "    \"No Hate/Toxic\": 0,\n",
    "    \"Toxic 1\": 1,\n",
    "    \"Toxic 2\": 2,\n",
    "    \"Toxic 3\": 3,\n",
    "    \"Hate 1\": 4,\n",
    "    \"Hate 2\": 5,\n",
    "    \"Hate 3\": 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E.Sin\\AppData\\Local\\Temp\\ipykernel_14260\\102145616.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"training_data_15k.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"training_data_15k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map string labels to integers\n",
    "df[\"Classification\"] = df[\"Classification\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      " Classification\n",
      "1    10500\n",
      "4    10500\n",
      "3    10500\n",
      "2    10500\n",
      "5    10500\n",
      "0    10500\n",
      "6    10500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set distribution:\n",
      " Classification\n",
      "3    2250\n",
      "1    2250\n",
      "6    2250\n",
      "2    2250\n",
      "5    2250\n",
      "0    2250\n",
      "4    2250\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      " Classification\n",
      "4    2250\n",
      "1    2250\n",
      "3    2250\n",
      "2    2250\n",
      "5    2250\n",
      "6    2250\n",
      "0    2250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stratified train-test split to maintain class balance\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df[\"Classification\"]\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"Classification\"]\n",
    ")\n",
    "\n",
    "# Check the class distribution in each split\n",
    "print(\"Training set distribution:\\n\", train_df[\"Classification\"].value_counts())\n",
    "print(\"\\nValidation set distribution:\\n\", val_df[\"Classification\"].value_counts())\n",
    "print(\"\\nTest set distribution:\\n\", test_df[\"Classification\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 7  # For multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=train_df[\"Classification\"].unique(),\n",
    "    y=train_df[\"Classification\"],\n",
    ")\n",
    "\n",
    "# Convert class weights to a tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Load configuration\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "# Set dropout rates and number of labels\n",
    "config.attention_probs_dropout_prob = 0.2  # Increase dropout rate\n",
    "config.hidden_dropout_prob = 0.2  # Increase dropout rate\n",
    "config.num_labels = 7  # Number of output classes\n",
    "\n",
    "# Initialize the model with the modified configuration\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-multilingual-cased\", config=config\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the model\n",
    "save_path = r\"C:\\Users\\E.Sin\\Desktop\\Richmond\\DSA4264-Detoxify\\model-1\\distilbert\\model\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of training steps\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Define warmup steps (e.g., 10% of total steps)\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "# Scheduler with warmup for the first X steps, then linear decay\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of training steps\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Define warmup steps (e.g., 10% of total steps)\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "# Scheduler with warmup for the first X steps, then linear decay\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training and Evaluation Functions with tqdm\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Wrap data_loader with tqdm to show progress\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Add scheduler step here\n",
    "\n",
    "        # Update progress bar description with running metrics\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": total_loss / (total_samples / BATCH_SIZE),\n",
    "                \"accuracy\": correct_predictions.double() / total_samples,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    return total_loss / len(data_loader), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [label for label, _ in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Wrap data_loader with tqdm to show progress during evaluation\n",
    "    progress_bar = tqdm(data_loader, desc=\"Validating\", unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "            # Update progress bar description with running metrics\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": total_loss / (total_samples / BATCH_SIZE),\n",
    "                    \"accuracy\": correct_predictions.double() / total_samples,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_samples\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    # Print classification report to get precision, recall, and F1 per class\n",
    "    class_report = classification_report(\n",
    "        all_labels, all_preds, target_names=class_names\n",
    "    )\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy.item(), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 575/575 [16:58<00:00,  1.77s/batch, loss=0.857, accuracy=tensor(0.6968, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8562, Train accuracy: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 124/124 [00:27<00:00,  4.56batch/s, loss=0.503, accuracy=tensor(0.8106, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.70      0.64      0.67      2250\n",
      "      Toxic 1       0.49      0.69      0.57      2250\n",
      "      Toxic 2       0.87      0.70      0.77      2250\n",
      "      Toxic 3       0.99      0.97      0.98      2250\n",
      "       Hate 1       0.78      0.77      0.77      2250\n",
      "       Hate 2       1.00      0.93      0.96      2250\n",
      "       Hate 3       1.00      0.99      0.99      2250\n",
      "\n",
      "     accuracy                           0.81     15750\n",
      "    macro avg       0.83      0.81      0.82     15750\n",
      " weighted avg       0.83      0.81      0.82     15750\n",
      "\n",
      "Validation loss: 0.4994, Validation accuracy: 0.8106, Validation F1: 0.8175\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 575/575 [16:16<00:00,  1.70s/batch, loss=0.463, accuracy=tensor(0.8280, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4624, Train accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 124/124 [00:27<00:00,  4.56batch/s, loss=0.466, accuracy=tensor(0.8263, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.76      0.66      0.71      2250\n",
      "      Toxic 1       0.54      0.67      0.60      2250\n",
      "      Toxic 2       0.86      0.72      0.79      2250\n",
      "      Toxic 3       0.99      0.97      0.98      2250\n",
      "       Hate 1       0.73      0.85      0.78      2250\n",
      "       Hate 2       1.00      0.93      0.96      2250\n",
      "       Hate 3       0.99      0.99      0.99      2250\n",
      "\n",
      "     accuracy                           0.83     15750\n",
      "    macro avg       0.84      0.83      0.83     15750\n",
      " weighted avg       0.84      0.83      0.83     15750\n",
      "\n",
      "Validation loss: 0.4627, Validation accuracy: 0.8263, Validation F1: 0.8299\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 575/575 [16:19<00:00,  1.70s/batch, loss=0.419, accuracy=tensor(0.8450, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4182, Train accuracy: 0.8450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 124/124 [00:26<00:00,  4.67batch/s, loss=0.459, accuracy=tensor(0.8281, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.74      0.69      0.72      2250\n",
      "      Toxic 1       0.55      0.67      0.60      2250\n",
      "      Toxic 2       0.88      0.71      0.79      2250\n",
      "      Toxic 3       0.99      0.98      0.98      2250\n",
      "       Hate 1       0.74      0.84      0.79      2250\n",
      "       Hate 2       1.00      0.93      0.96      2250\n",
      "       Hate 3       1.00      0.99      0.99      2250\n",
      "\n",
      "     accuracy                           0.83     15750\n",
      "    macro avg       0.84      0.83      0.83     15750\n",
      " weighted avg       0.84      0.83      0.83     15750\n",
      "\n",
      "Validation loss: 0.4555, Validation accuracy: 0.8281, Validation F1: 0.8320\n",
      "Best model saved at C:\\Users\\E.Sin\\Desktop\\Richmond\\DSA4264-Detoxify\\model-1\\distilbert\\model\\best_distilbert_model.pth with validation loss: 0.4555\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable to track the best validation loss\n",
    "best_val_loss = float(\"inf\")  # Start with a very high value\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # Pass the scheduler to train_epoch\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, optimizer, criterion, device, scheduler\n",
    "    )\n",
    "    print(f\"Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    val_loss, val_acc, val_f1 = eval_model(model, val_loader, criterion, device)\n",
    "    print(\n",
    "        f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}, Validation F1: {val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check if the current validation loss is better than the best we've seen\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss  # Update the best validation loss\n",
    "        best_model = model.state_dict()  # Save the current model state\n",
    "\n",
    "# Save the best model after training\n",
    "model_save_path = os.path.join(save_path, \"best_distilbert_model.pth\")\n",
    "torch.save(best_model, model_save_path)\n",
    "print(\n",
    "    f\"Best model saved at {model_save_path} with validation loss: {best_val_loss:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact length of test data: 15750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 124/124 [00:27<00:00,  4.44batch/s, loss=0.451, accuracy=tensor(0.8324, device='cuda:0', dtype=torch.float64)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "No Hate/Toxic       0.73      0.70      0.72      2250\n",
      "      Toxic 1       0.56      0.68      0.61      2250\n",
      "      Toxic 2       0.88      0.71      0.79      2250\n",
      "      Toxic 3       0.99      0.98      0.98      2250\n",
      "       Hate 1       0.76      0.83      0.79      2250\n",
      "       Hate 2       1.00      0.94      0.97      2250\n",
      "       Hate 3       0.99      0.99      0.99      2250\n",
      "\n",
      "     accuracy                           0.83     15750\n",
      "    macro avg       0.84      0.83      0.84     15750\n",
      " weighted avg       0.84      0.83      0.84     15750\n",
      "\n",
      "Test loss: 0.4470, Test accuracy: 0.8324, Test F1: 0.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the Model on Test Set\n",
    "# Print the size of the test dataset\n",
    "test_data_size = len(test_loader.dataset)\n",
    "print(f\"Exact length of test data: {test_data_size}\\n\")  # Added new line for clarity\n",
    "\n",
    "# Evaluate the model on the test set and print metrics\n",
    "test_loss, test_acc, test_f1 = eval_model(model, test_loader, criterion, device)\n",
    "print(\n",
    "    f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
