{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yi\n",
      "[nltk_data]     Jing\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Yi\n",
      "[nltk_data]     Jing\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from better_profanity import profanity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../full_data_with_topic_-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default NLTK English stop words\n",
    "nltk_stop_words = stopwords.words(\"english\")\n",
    "custom_stop_words = [\n",
    "    \"hes\",\n",
    "    \"shes\",\n",
    "    \"singapore\",\n",
    "    \"singaporean\",\n",
    "    \"sg\",\n",
    "    \"singaporeans\",\n",
    "    \"man\",\n",
    "    \"woman\",\n",
    "]\n",
    "\n",
    "combined_stop_words = set(nltk_stop_words + custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                link  \\\n",
      "0  /r/singapore/comments/gyxf42/the_myth_of_syste...   \n",
      "1  /r/SingaporeRaw/comments/swdnv3/its_funny_beca...   \n",
      "2  /r/singapore/comments/rotpqm/moh_debunks_bloom...   \n",
      "3  /r/singapore/comments/rpixyb/spore_must_expect...   \n",
      "4  /r/singapore/comments/oi613v/man_to_be_charged...   \n",
      "\n",
      "                                         Title_Words  \n",
      "0     [the, myth, of, systemic, police, racism, wsj]  \n",
      "1                   [its, funny, because, its, true]  \n",
      "2     [moh, debunks, bloombergs, claim, that, spore]  \n",
      "3  [spore, must, expect, new, wave, of, covid19, ...  \n",
      "4  [man, to, be, charged, for, criminal, trespass...  \n"
     ]
    }
   ],
   "source": [
    "def extract_title_words(link):\n",
    "    # Use regex to find the title in the link\n",
    "    match = re.search(r\"/comments/[^/]+/([^/]+)/\", link)\n",
    "    if match:\n",
    "        title = match.group(1).replace(\"_\", \" \")  # Replace underscores with spaces\n",
    "        words = title.split()  # Split the title into individual words\n",
    "        return words\n",
    "    return []\n",
    "\n",
    "\n",
    "# Apply the function to the 'link' column and create a new column 'Title_Words'\n",
    "df1[\"Title_Words\"] = df1[\"link\"].apply(extract_title_words)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df1[[\"link\", \"Title_Words\"]].head())\n",
    "df1.to_csv(\"subset_df_with_reddit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where Title_Words is equal to the specific list\n",
    "df1 = df1[\n",
    "    ~df1[\"Title_Words\"].apply(\n",
    "        lambda x: x\n",
    "        == [\"rsingapore\", \"random\", \"discussion\", \"and\", \"small\", \"questions\"]\n",
    "        or x == [\"deleted\", \"by\", \"user\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def clean_title_words(title_words):\n",
    "    # Convert list of words to lowercase\n",
    "    title_words = [word.lower() for word in title_words]\n",
    "\n",
    "    # Remove stop words\n",
    "    cleaned_words = [word for word in title_words if word not in combined_stop_words]\n",
    "\n",
    "    return cleaned_words\n",
    "\n",
    "\n",
    "df1[\"Title_Words\"] = df1[\"Title_Words\"].apply(clean_title_words)\n",
    "df1[\"title_words_str\"] = df1[\"Title_Words\"].apply(lambda x: \" \".join(x))\n",
    "texts = df1[\"title_words_str\"].tolist()\n",
    "\n",
    "# 2. Perform topic modeling on the title words, clustering into 15 topics\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # embedding\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=10,\n",
    "    n_components=3,\n",
    "    min_dist=0.1,\n",
    "    metric=\"cosine\",\n",
    "    random_state=31,  ##can experiment with bigger clusters\n",
    ")\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=20,\n",
    "    min_samples=1,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=True,\n",
    ")\n",
    "representation_model = KeyBERTInspired()\n",
    "# train the bertopic model\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=sentence_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    nr_topics=30,\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3384</td>\n",
       "      <td>-1_dining_polling_group_elections</td>\n",
       "      <td>[dining, polling, group, elections, 2020, resu...</td>\n",
       "      <td>[covid19 diningin group size back 2 groups 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1626</td>\n",
       "      <td>0_singapores_malaysians_chinese_malaysian</td>\n",
       "      <td>[singapores, malaysians, chinese, malaysian, t...</td>\n",
       "      <td>[chinese formed 75 singapores, chinese formed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1278</td>\n",
       "      <td>1_unpopular_opinion_discussion_wrong</td>\n",
       "      <td>[unpopular, opinion, discussion, wrong, though...</td>\n",
       "      <td>[unpopular opinion good thing, unpopular opini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1006</td>\n",
       "      <td>2_jail_jailed_arrest_detained</td>\n",
       "      <td>[jail, jailed, arrest, detained, probation, ar...</td>\n",
       "      <td>[6 months jail police officer took, gets jail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>501</td>\n",
       "      <td>3_ns_serve_women_females</td>\n",
       "      <td>[ns, serve, women, females, ladies, gender, me...</td>\n",
       "      <td>[real reason women serve ns, dont women serve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>493</td>\n",
       "      <td>4_fairprice_delivery_bags_ikea</td>\n",
       "      <td>[fairprice, delivery, bags, ikea, food, shoppi...</td>\n",
       "      <td>[fairprice starts selling plastic bags 4, fair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>474</td>\n",
       "      <td>5_sporean_sporeans_spore_race</td>\n",
       "      <td>[sporean, sporeans, spore, race, spores, racia...</td>\n",
       "      <td>[sporean rejected renting due race, sporean re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>407</td>\n",
       "      <td>6_pap_paps_candidate_2020</td>\n",
       "      <td>[pap, paps, candidate, 2020, ge2020, ge, polit...</td>\n",
       "      <td>[pap ge 2020 candidate says people misundersto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>405</td>\n",
       "      <td>7_covid19_coronavirus_covid_outbreak</td>\n",
       "      <td>[covid19, coronavirus, covid, outbreak, pandem...</td>\n",
       "      <td>[coronavirus record 120 new covid19 cases spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>393</td>\n",
       "      <td>8_racism_racist_racial_racists</td>\n",
       "      <td>[racism, racist, racial, racists, discriminati...</td>\n",
       "      <td>[racism, racism, racism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>390</td>\n",
       "      <td>9_salary_salaries_8000_wage</td>\n",
       "      <td>[salary, salaries, 8000, wage, ends, hiring, p...</td>\n",
       "      <td>[looking mr right 8000 salary ends, looking mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>381</td>\n",
       "      <td>10_mrt_trains_buses_train</td>\n",
       "      <td>[mrt, trains, buses, train, bus, commuters, fa...</td>\n",
       "      <td>[mrt scam, mrt train asks fellow commuters, mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>327</td>\n",
       "      <td>11_rally_protest_protests_2021</td>\n",
       "      <td>[rally, protest, protests, 2021, megathread, 2...</td>\n",
       "      <td>[megathread national day rally 2022, megathrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>298</td>\n",
       "      <td>12_scam_scams_scammer_scammers</td>\n",
       "      <td>[scam, scams, scammer, scammers, spam, legit, ...</td>\n",
       "      <td>[received scam whatsapp call overseas, going s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>287</td>\n",
       "      <td>13_hdb_hdbs_flats_singles</td>\n",
       "      <td>[hdb, hdbs, flats, singles, rental, rent, resi...</td>\n",
       "      <td>[singles apply new hdb flats, singles apply ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>257</td>\n",
       "      <td>14_student_students_nus_universities</td>\n",
       "      <td>[student, students, nus, universities, schools...</td>\n",
       "      <td>[nus student pleads guilty taking illicit, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>213</td>\n",
       "      <td>15_starved_maid_maids_killing</td>\n",
       "      <td>[starved, maid, maids, killing, 24kg, fatal, a...</td>\n",
       "      <td>[admits killing maid starved 24kg, admits kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>180</td>\n",
       "      <td>16_singh_pritam_khan_singhs</td>\n",
       "      <td>[singh, pritam, khan, singhs, raeesah, indian,...</td>\n",
       "      <td>[raeesah khan started mess pritam singh, raees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>159</td>\n",
       "      <td>17_ns_noc_nocs_nsf</td>\n",
       "      <td>[ns, noc, nocs, nsf, sylvias, sylvia, nsfs, ns...</td>\n",
       "      <td>[noc saga sylvia vs ryan, ns, ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>118</td>\n",
       "      <td>18_masks_maskwearing_mask_maskless</td>\n",
       "      <td>[masks, maskwearing, mask, maskless, wear, ref...</td>\n",
       "      <td>[sovereign briton refused wear mask, sovereign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>111</td>\n",
       "      <td>19_service_national_reminder_citizens</td>\n",
       "      <td>[service, national, reminder, citizens, citize...</td>\n",
       "      <td>[reminder national service, help national serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>106</td>\n",
       "      <td>20_hypocrites_shanmugams_shanmugam_amos</td>\n",
       "      <td>[hypocrites, shanmugams, shanmugam, amos, shan...</td>\n",
       "      <td>[shanmugam labels amos yees supporters hypocri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>105</td>\n",
       "      <td>21_gong_clangs_neighbour_attacked</td>\n",
       "      <td>[gong, clangs, neighbour, attacked, noise, boa...</td>\n",
       "      <td>[neighbour clangs gong repeatedly spore, neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>101</td>\n",
       "      <td>22_children_couples_kids_couple</td>\n",
       "      <td>[children, couples, kids, couple, raise, polyg...</td>\n",
       "      <td>[couple raise 5 young children combined food, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>74</td>\n",
       "      <td>23_population_shrinks_singapores_decrease</td>\n",
       "      <td>[population, shrinks, singapores, decrease, 54...</td>\n",
       "      <td>[singapores population shrinks 545 million, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>61</td>\n",
       "      <td>24_taxgst_gst_tax_taxes</td>\n",
       "      <td>[taxgst, gst, tax, taxes, trickledown, jamus, ...</td>\n",
       "      <td>[wp mp jamus lim proposes wealth tax 05 2, wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>25_healing_iris_antivaxxer_antivaxxers</td>\n",
       "      <td>[healing, iris, antivaxxer, antivaxxers, antiv...</td>\n",
       "      <td>[iris koh healing divide angry bus, found anti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>26_bomb_explosion_detonation_blast</td>\n",
       "      <td>[bomb, explosion, detonation, blast, wwii, ter...</td>\n",
       "      <td>[wwii bomb unearthed condominium site, terrapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27_tracetogether_tracetogethersg_trace_safeentry</td>\n",
       "      <td>[tracetogether, tracetogethersg, trace, safeen...</td>\n",
       "      <td>[tracetogether data use police restricted, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>28_fights_fight_fighting_bigger</td>\n",
       "      <td>[fights, fight, fighting, bigger, mayweather, ...</td>\n",
       "      <td>[dont pick fights people bigger, dont pick fig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                              Name  \\\n",
       "0      -1   3384                 -1_dining_polling_group_elections   \n",
       "1       0   1626         0_singapores_malaysians_chinese_malaysian   \n",
       "2       1   1278              1_unpopular_opinion_discussion_wrong   \n",
       "3       2   1006                     2_jail_jailed_arrest_detained   \n",
       "4       3    501                          3_ns_serve_women_females   \n",
       "5       4    493                    4_fairprice_delivery_bags_ikea   \n",
       "6       5    474                     5_sporean_sporeans_spore_race   \n",
       "7       6    407                         6_pap_paps_candidate_2020   \n",
       "8       7    405              7_covid19_coronavirus_covid_outbreak   \n",
       "9       8    393                    8_racism_racist_racial_racists   \n",
       "10      9    390                       9_salary_salaries_8000_wage   \n",
       "11     10    381                         10_mrt_trains_buses_train   \n",
       "12     11    327                    11_rally_protest_protests_2021   \n",
       "13     12    298                    12_scam_scams_scammer_scammers   \n",
       "14     13    287                         13_hdb_hdbs_flats_singles   \n",
       "15     14    257              14_student_students_nus_universities   \n",
       "16     15    213                     15_starved_maid_maids_killing   \n",
       "17     16    180                       16_singh_pritam_khan_singhs   \n",
       "18     17    159                                17_ns_noc_nocs_nsf   \n",
       "19     18    118                18_masks_maskwearing_mask_maskless   \n",
       "20     19    111             19_service_national_reminder_citizens   \n",
       "21     20    106           20_hypocrites_shanmugams_shanmugam_amos   \n",
       "22     21    105                 21_gong_clangs_neighbour_attacked   \n",
       "23     22    101                   22_children_couples_kids_couple   \n",
       "24     23     74         23_population_shrinks_singapores_decrease   \n",
       "25     24     61                           24_taxgst_gst_tax_taxes   \n",
       "26     25     59            25_healing_iris_antivaxxer_antivaxxers   \n",
       "27     26     57                26_bomb_explosion_detonation_blast   \n",
       "28     27     28  27_tracetogether_tracetogethersg_trace_safeentry   \n",
       "29     28     20                   28_fights_fight_fighting_bigger   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [dining, polling, group, elections, 2020, resu...   \n",
       "1   [singapores, malaysians, chinese, malaysian, t...   \n",
       "2   [unpopular, opinion, discussion, wrong, though...   \n",
       "3   [jail, jailed, arrest, detained, probation, ar...   \n",
       "4   [ns, serve, women, females, ladies, gender, me...   \n",
       "5   [fairprice, delivery, bags, ikea, food, shoppi...   \n",
       "6   [sporean, sporeans, spore, race, spores, racia...   \n",
       "7   [pap, paps, candidate, 2020, ge2020, ge, polit...   \n",
       "8   [covid19, coronavirus, covid, outbreak, pandem...   \n",
       "9   [racism, racist, racial, racists, discriminati...   \n",
       "10  [salary, salaries, 8000, wage, ends, hiring, p...   \n",
       "11  [mrt, trains, buses, train, bus, commuters, fa...   \n",
       "12  [rally, protest, protests, 2021, megathread, 2...   \n",
       "13  [scam, scams, scammer, scammers, spam, legit, ...   \n",
       "14  [hdb, hdbs, flats, singles, rental, rent, resi...   \n",
       "15  [student, students, nus, universities, schools...   \n",
       "16  [starved, maid, maids, killing, 24kg, fatal, a...   \n",
       "17  [singh, pritam, khan, singhs, raeesah, indian,...   \n",
       "18  [ns, noc, nocs, nsf, sylvias, sylvia, nsfs, ns...   \n",
       "19  [masks, maskwearing, mask, maskless, wear, ref...   \n",
       "20  [service, national, reminder, citizens, citize...   \n",
       "21  [hypocrites, shanmugams, shanmugam, amos, shan...   \n",
       "22  [gong, clangs, neighbour, attacked, noise, boa...   \n",
       "23  [children, couples, kids, couple, raise, polyg...   \n",
       "24  [population, shrinks, singapores, decrease, 54...   \n",
       "25  [taxgst, gst, tax, taxes, trickledown, jamus, ...   \n",
       "26  [healing, iris, antivaxxer, antivaxxers, antiv...   \n",
       "27  [bomb, explosion, detonation, blast, wwii, ter...   \n",
       "28  [tracetogether, tracetogethersg, trace, safeen...   \n",
       "29  [fights, fight, fighting, bigger, mayweather, ...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [covid19 diningin group size back 2 groups 5, ...  \n",
       "1   [chinese formed 75 singapores, chinese formed ...  \n",
       "2   [unpopular opinion good thing, unpopular opini...  \n",
       "3   [6 months jail police officer took, gets jail ...  \n",
       "4   [real reason women serve ns, dont women serve ...  \n",
       "5   [fairprice starts selling plastic bags 4, fair...  \n",
       "6   [sporean rejected renting due race, sporean re...  \n",
       "7   [pap ge 2020 candidate says people misundersto...  \n",
       "8   [coronavirus record 120 new covid19 cases spor...  \n",
       "9                            [racism, racism, racism]  \n",
       "10  [looking mr right 8000 salary ends, looking mr...  \n",
       "11  [mrt scam, mrt train asks fellow commuters, mr...  \n",
       "12  [megathread national day rally 2022, megathrea...  \n",
       "13  [received scam whatsapp call overseas, going s...  \n",
       "14  [singles apply new hdb flats, singles apply ne...  \n",
       "15  [nus student pleads guilty taking illicit, sec...  \n",
       "16  [admits killing maid starved 24kg, admits kill...  \n",
       "17  [raeesah khan started mess pritam singh, raees...  \n",
       "18                  [noc saga sylvia vs ryan, ns, ns]  \n",
       "19  [sovereign briton refused wear mask, sovereign...  \n",
       "20  [reminder national service, help national serv...  \n",
       "21  [shanmugam labels amos yees supporters hypocri...  \n",
       "22  [neighbour clangs gong repeatedly spore, neigh...  \n",
       "23  [couple raise 5 young children combined food, ...  \n",
       "24  [singapores population shrinks 545 million, si...  \n",
       "25  [wp mp jamus lim proposes wealth tax 05 2, wea...  \n",
       "26  [iris koh healing divide angry bus, found anti...  \n",
       "27  [wwii bomb unearthed condominium site, terrapi...  \n",
       "28  [tracetogether data use police restricted, tra...  \n",
       "29  [dont pick fights people bigger, dont pick fig...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic -1: dining, group, people, social, cut, society, think, public, workers, men\n",
      "Topic 0: racism, racist, racial, discrimination, interracial, asian, xenophobia, chinese, foreigners, white\n",
      "Topic 1: jail, jailed, arrest, detained, arrested, rape, offender, assault, raping, raped\n",
      "Topic 2: unpopular, opinion, discussion, parents, thoughts, wrong, parental, say, commentary, think\n",
      "Topic 3: raeesah, khan, singh, committee, privileges, mp, mps, candidate, statement, incident\n",
      "Topic 4: covid19, coronavirus, covid, outbreak, pandemic, virus, viral, infected, endemic, infection\n",
      "Topic 5: ns, women, serve, females, ladies, gender, men, female, sex, national\n",
      "Topic 6: food, foodpanda, meal, ikea, mcdonalds, snacks, delivery, trays, rice, diners\n",
      "Topic 7: sporean, spore, sporeans, spores, church, influenced, ad, rsingapore, grabfood, race\n",
      "Topic 8: salary, salaries, 8000, wage, ends, hiring, pay, hr, jobs, careers\n",
      "Topic 9: mrt, trains, train, commuters, buses, fares, bus, transport, station, passenger\n",
      "Topic 10: hdb, hdbs, flats, singles, flat, residential, affordable, housing, apply, rents\n",
      "Topic 11: student, nus, students, masturbating, schools, pleads, school, universities, university, guilty\n",
      "Topic 12: starved, maid, maids, killing, 24kg, fatal, abuses, death, 34k, forced\n",
      "Topic 13: population, shrinks, singapores, 545, fewer, drop, drops, million, people, 592\n",
      "Topic 14: ns, noc, nocs, nsf, sylvias, sylvia, nsfs, nsman, ryan, saga\n",
      "Topic 15: service, national, reminder, citizens, citizen, conscription, military, serve, army, soldiers\n",
      "Topic 16: gong, clangs, neighbour, spore, attacked, noise, boar, mosquito, mosquitoes, crow\n",
      "Topic 17: bomb, explosion, detonation, blast, wwii, terrorist, threat, terror, terrapin, threats\n",
      "Topic 18: fights, fight, fighting, bigger, mayweather, pick, martial, mcgregor, large, big\n"
     ]
    }
   ],
   "source": [
    "## input topics to merge here\n",
    "topics_to_merge = [\n",
    "    [6, 11, 16, 24, 20],\n",
    "    [23, 22],\n",
    "    [\n",
    "        18,\n",
    "        7,\n",
    "    ],\n",
    "    [27, 25, 18, 7],\n",
    "    [12, 2],\n",
    "    [8, 0],\n",
    "]\n",
    "\n",
    "\n",
    "topic_model.merge_topics(texts, topics_to_merge)\n",
    "\n",
    "# check topics after merging\n",
    "topic_keywords = {}\n",
    "for topic_num in sorted(topic_model.get_topics()):\n",
    "    try:\n",
    "        words, scores = zip(*topic_model.get_topic(topic_num))\n",
    "        topic_keywords[topic_num] = \", \".join(words)\n",
    "        print(f\"Topic {topic_num}: {', '.join(words)}\")\n",
    "    except ValueError:\n",
    "        print(f\"No words found for Topic {topic_num}, skipping...\")\n",
    "        topic_keywords[topic_num] = \"No relevant words\"  # Handling topics without words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_topics, _ = topic_model.transform(\n",
    "    texts\n",
    ")  # Replace with your relevant text column\n",
    "\n",
    "# Step 3: Add the updated topics to df1\n",
    "df1[\"Updated_Topic\"] = updated_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"to_see.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text            timestamp  \\\n",
      "0  It's a claim that is well supported by various...       6/8/2020 11:37   \n",
      "1  Why come all the way here and complain dipshit...       20/2/2022 2:21   \n",
      "2  You mean like their 'right' to lie and malign ...     12/26/2021 13:33   \n",
      "3  Here we go again with the fear mongering. Can'...     27/12/2021 15:29   \n",
      "4  Idiot. Fucking lucky the rhino did not just ch...  2021-07-11 15:12:52   \n",
      "\n",
      "            username                                               link  \\\n",
      "0  Talkingtomytoilet  /r/singapore/comments/gyxf42/the_myth_of_syste...   \n",
      "1           viviseca  /r/SingaporeRaw/comments/swdnv3/its_funny_beca...   \n",
      "2               sec5  /r/singapore/comments/rotpqm/moh_debunks_bloom...   \n",
      "3  Typical_Leave1988  /r/singapore/comments/rpixyb/spore_must_expect...   \n",
      "4          LaZZyBird  /r/singapore/comments/oi613v/man_to_be_charged...   \n",
      "\n",
      "     link_id   parent_id       id subreddit_id  \\\n",
      "0  t3_gyxf42  t1_ftcyjev  ftczbxh     t5_2qh8c   \n",
      "1  t3_swdnv3  t1_hxn3238  hxnl9cs     t5_xnx04   \n",
      "2  t3_rotpqm  t1_hq0pbt4  hq0un1f     t5_2qh8c   \n",
      "3  t3_rpixyb   t3_rpixyb  hq5lhuj     t5_2qh8c   \n",
      "4  t3_oi613v   t3_oi613v  h4tcl8o     t5_2qh8c   \n",
      "\n",
      "                                          moderation  year  ...  \\\n",
      "0  {'removal_reason': None, 'collapsed': False, '...  2020  ...   \n",
      "1  {'controversiality': 0, 'collapsed_reason_code...  2022  ...   \n",
      "2  {'collapsed_reason_code': 'LOW_SCORE', 'collap...  2021  ...   \n",
      "3  {'collapsed_reason_code': None, 'collapsed_rea...  2021  ...   \n",
      "4  {'collapsed_reason_code': None, 'collapsed_rea...  2021  ...   \n",
      "\n",
      "   Sensitive Group Classification  \\\n",
      "0              Yes         Hate 1   \n",
      "1              Yes         Hate 2   \n",
      "2               No        Toxic 1   \n",
      "3              Yes        Toxic 2   \n",
      "4               No        Toxic 2   \n",
      "\n",
      "                                          clean_text custom_topic  \\\n",
      "0  claim well supported various studies blm hand ...           -1   \n",
      "1  come way complain dipshit pajeet ape enjoy lif...           -1   \n",
      "2  mean like right lie malign without evidence proof           -1   \n",
      "3  go fear mongering cant stand annoyingly propag...           -1   \n",
      "4           idiot fucking lucky rhino charge ram ass           -1   \n",
      "\n",
      "                                         Topic_Words  \\\n",
      "0  singaporean, singapore, race, countries, cant,...   \n",
      "1  singaporean, singapore, race, countries, cant,...   \n",
      "2  singaporean, singapore, race, countries, cant,...   \n",
      "3  singaporean, singapore, race, countries, cant,...   \n",
      "4  singaporean, singapore, race, countries, cant,...   \n",
      "\n",
      "                                        Title_Words  \\\n",
      "0             [myth, systemic, police, racism, wsj]   \n",
      "1                                     [funny, true]   \n",
      "2          [moh, debunks, bloombergs, claim, spore]   \n",
      "3  [spore, must, expect, new, wave, covid19, cases]   \n",
      "4                     [charged, criminal, trespass]   \n",
      "\n",
      "                            title_words_str Updated_Topic  Final Topic  \\\n",
      "0           myth systemic police racism wsj             0            1   \n",
      "1                                funny true            -1           -1   \n",
      "2        moh debunks bloombergs claim spore             6           -1   \n",
      "3  spore must expect new wave covid19 cases             4            6   \n",
      "4                 charged criminal trespass             1            9   \n",
      "\n",
      "   Final Topic Name  \n",
      "0            Racism  \n",
      "1           Outlier  \n",
      "2           Outlier  \n",
      "3          COVID-19  \n",
      "4            Crimes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_mapping = {\n",
    "    0: (1, \"Racism\"),\n",
    "    # 6: (2, \"Religion\"),\n",
    "    # : (3, \"Generational\"),\n",
    "    # 8: (4, \"LGBTQ+\"),\n",
    "    8: (5, \"Work\"),\n",
    "    4: (6, \"COVID-19\"),\n",
    "    5: (7, \"Gender\"),\n",
    "    3: (8, \"Government\"),\n",
    "    1: (9, \"Crimes\"),\n",
    "    10: (10, \"Housing\"),\n",
    "    9: (11, \"Transportation\"),\n",
    "    11: (12, \"Education\"),\n",
    "}\n",
    "\n",
    "# Step 2: Create new columns based on the mapping\n",
    "\n",
    "\n",
    "def map_final_topics(updated_topic):\n",
    "    if updated_topic in topic_mapping:\n",
    "        return topic_mapping[updated_topic]\n",
    "    else:\n",
    "        return (None, \"None\")\n",
    "\n",
    "\n",
    "# Apply the mapping to create new columns\n",
    "df1[[\"Final Topic\", \"Final Topic Name\"]] = (\n",
    "    df1[\"Updated_Topic\"].apply(map_final_topics).apply(pd.Series)\n",
    ")\n",
    "\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text            timestamp  \\\n",
      "0  It's a claim that is well supported by various...       6/8/2020 11:37   \n",
      "1  Why come all the way here and complain dipshit...       20/2/2022 2:21   \n",
      "2  You mean like their 'right' to lie and malign ...     12/26/2021 13:33   \n",
      "3  Here we go again with the fear mongering. Can'...     27/12/2021 15:29   \n",
      "4  Idiot. Fucking lucky the rhino did not just ch...  2021-07-11 15:12:52   \n",
      "\n",
      "            username                                               link  \\\n",
      "0  Talkingtomytoilet  /r/singapore/comments/gyxf42/the_myth_of_syste...   \n",
      "1           viviseca  /r/SingaporeRaw/comments/swdnv3/its_funny_beca...   \n",
      "2               sec5  /r/singapore/comments/rotpqm/moh_debunks_bloom...   \n",
      "3  Typical_Leave1988  /r/singapore/comments/rpixyb/spore_must_expect...   \n",
      "4          LaZZyBird  /r/singapore/comments/oi613v/man_to_be_charged...   \n",
      "\n",
      "     link_id   parent_id       id subreddit_id  \\\n",
      "0  t3_gyxf42  t1_ftcyjev  ftczbxh     t5_2qh8c   \n",
      "1  t3_swdnv3  t1_hxn3238  hxnl9cs     t5_xnx04   \n",
      "2  t3_rotpqm  t1_hq0pbt4  hq0un1f     t5_2qh8c   \n",
      "3  t3_rpixyb   t3_rpixyb  hq5lhuj     t5_2qh8c   \n",
      "4  t3_oi613v   t3_oi613v  h4tcl8o     t5_2qh8c   \n",
      "\n",
      "                                          moderation  year  word_count  \\\n",
      "0  {'removal_reason': None, 'collapsed': False, '...  2020        21.0   \n",
      "1  {'controversiality': 0, 'collapsed_reason_code...  2022        33.0   \n",
      "2  {'collapsed_reason_code': 'LOW_SCORE', 'collap...  2021        13.0   \n",
      "3  {'collapsed_reason_code': None, 'collapsed_rea...  2021        27.0   \n",
      "4  {'collapsed_reason_code': None, 'collapsed_rea...  2021        16.0   \n",
      "\n",
      "  Sensitive Group Classification  \\\n",
      "0             Yes         Hate 1   \n",
      "1             Yes         Hate 2   \n",
      "2              No        Toxic 1   \n",
      "3             Yes        Toxic 2   \n",
      "4              No        Toxic 2   \n",
      "\n",
      "                                          clean_text  custom_topic  \\\n",
      "0  claim well supported various studies blm hand ...            -1   \n",
      "1  come way complain dipshit pajeet ape enjoy lif...            -1   \n",
      "2  mean like right lie malign without evidence proof            -1   \n",
      "3  go fear mongering cant stand annoyingly propag...            -1   \n",
      "4           idiot fucking lucky rhino charge ram ass            -1   \n",
      "\n",
      "                                         Topic_Words  Updated_Topic  \\\n",
      "0  singaporean, singapore, race, countries, cant,...              0   \n",
      "1  singaporean, singapore, race, countries, cant,...             -1   \n",
      "2  singaporean, singapore, race, countries, cant,...              6   \n",
      "3  singaporean, singapore, race, countries, cant,...              4   \n",
      "4  singaporean, singapore, race, countries, cant,...              1   \n",
      "\n",
      "   Final Topic Final Topic Name  \n",
      "0            1           Racism  \n",
      "1           -1          Outlier  \n",
      "2           -1          Outlier  \n",
      "3            6         COVID-19  \n",
      "4            9           Crimes  \n"
     ]
    }
   ],
   "source": [
    "df1 = df1.drop(columns=[\"Title_Words\", \"title_words_str\"])\n",
    "\n",
    "# Optional: Display the updated DataFrame to confirm the columns are removed\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"topics_-1_redistribute.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA4264-Detoxify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
