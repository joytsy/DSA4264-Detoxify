{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for Hate 3 sentences (10 templates)\n",
    "hate_3_templates = [\n",
    "    \"If {group} dont {action}, theyll pay when I {threat}.\",\n",
    "    \"I will {threat} if those {group} {action}.\",\n",
    "    \"These {group} need to {action}, or else I'll {threat}.\",\n",
    "    \"If those {group} don't {action}, they'll regret it because I'll {threat}.\",\n",
    "    \"{group} who refuse to {action} deserve to {threat}.\",\n",
    "    \"{group} better {action}, or they will {threat}.\",\n",
    "    \"The only solution is to {threat} if those {group} keep {action}.\",\n",
    "    \"If {group} dont {action}, I swear Ill {threat}.\",\n",
    "    \"I'll {threat} if those {group} dont {action} immediately.\",\n",
    "    \"{group} must {action}, or else Ill {threat} and make them regret it.\",\n",
    "]\n",
    "\n",
    "# Define potential groups targeted in hate speech (7 groups)\n",
    "groups = [\n",
    "    \"immigrants\",\n",
    "    \"women\",\n",
    "    \"LGBTQ+ people\",\n",
    "    \"Buddhist people\",\n",
    "    \"disabled people\",\n",
    "    \"Black people\",\n",
    "    \"Asians\",\n",
    "]\n",
    "\n",
    "# Define potential actions (15 actions)\n",
    "actions = [\n",
    "    \"leave\",\n",
    "    \"go back to their country\",\n",
    "    \"stop taking our jobs\",\n",
    "    \"stay out of our neighborhoods\",\n",
    "    \"stop being lazy\",\n",
    "    \"stop corrupting our youth\",\n",
    "    \"stop pushing their agenda\",\n",
    "    \"disappear\",\n",
    "    \"leave the city\",\n",
    "    \"stay away from our schools\",\n",
    "    \"stop poisoning our culture\",\n",
    "    \"stop stealing from us\",\n",
    "    \"stop spreading lies\",\n",
    "    \"stop crossing our borders\",\n",
    "    \"stay away from our families\",\n",
    "]\n",
    "\n",
    "# Define potential threats (10 threats)\n",
    "threats = [\n",
    "    \"make their lives miserable\",\n",
    "    \"find them and hurt them\",\n",
    "    \"make sure they suffer\",\n",
    "    \"ensure they face consequences\",\n",
    "    \"destroy everything they have\",\n",
    "    \"make them pay\",\n",
    "    \"ruin their families\",\n",
    "    \"break their bones\",\n",
    "    \"burn their houses\",\n",
    "    \"drive them out\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Cartesian product of all combinations\n",
    "\n",
    "\n",
    "def generate_deterministic_hate_3_comments():\n",
    "    combinations = itertools.product(hate_3_templates, groups, actions, threats)\n",
    "    comments = [\n",
    "        template.format(group=group, action=action, threat=threat)\n",
    "        for template, group, action, threat in combinations\n",
    "    ]\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique ID (e.g., comment id)\n",
    "\n",
    "\n",
    "def generate_unique_comment_id():\n",
    "    return \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz0123456789\", k=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique link ID (e.g., \"t3_\" followed by 6 characters)\n",
    "\n",
    "\n",
    "def generate_unique_link_id():\n",
    "    return \"t3_\" + \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz0123456789\", k=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random timestamp (date and time) in 2023\n",
    "\n",
    "\n",
    "def generate_random_timestamp(year=2023):\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31)\n",
    "    random_date = start_date + timedelta(\n",
    "        days=random.randint(0, (end_date - start_date).days)\n",
    "    )\n",
    "\n",
    "    # Generate random hours, minutes, and seconds\n",
    "    random_time = timedelta(\n",
    "        hours=random.randint(0, 23),\n",
    "        minutes=random.randint(0, 59),\n",
    "        seconds=random.randint(0, 59),\n",
    "    )\n",
    "\n",
    "    # Combine the random date with the random time\n",
    "    full_random_datetime = random_date + random_time\n",
    "\n",
    "    # Return in the desired format\n",
    "    return full_random_datetime.strftime(\"%m/%d/%Y %I:%M:%S %p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random 6-letter username (alphabets only)\n",
    "\n",
    "\n",
    "def generate_username():\n",
    "    return \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz\", k=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5000 deterministic comments\n",
    "hate_3_data = generate_deterministic_hate_3_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file columns\n",
    "csv_columns = [\n",
    "    \"text\",\n",
    "    \"timestamp\",\n",
    "    \"username\",\n",
    "    \"link\",\n",
    "    \"link_id\",\n",
    "    \"parent_id\",\n",
    "    \"id\",\n",
    "    \"subreddit_id\",\n",
    "    \"moderation\",\n",
    "    \"year\",\n",
    "    \"concatenated_count\",\n",
    "    \"complete_thread\",\n",
    "    \"gold_label\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant values\n",
    "subreddit_id = \"t5_2qh8c\"\n",
    "moderation = \"{'controversiality': 0, 'collapsed_reason_code': None, 'collapsed': False, 'collapsed_reason': None}\"\n",
    "year = \"2023\"\n",
    "concatenated_count = 1\n",
    "complete_thread = True\n",
    "gold_label = \"Hate 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare rows for CSV\n",
    "csv_data = []\n",
    "for i in range(10500):\n",
    "    text = hate_3_data[i]\n",
    "    timestamp = generate_random_timestamp()\n",
    "    username = generate_username()\n",
    "    link_id = generate_unique_link_id()\n",
    "    parent_id = link_id  # Same within each row\n",
    "    comment_id = generate_unique_comment_id()\n",
    "    link = f\"/r/singapore/comments/13c3mt8/Strict_appearance_and_grooming_standards_for_Singapore_Airlines_cabin_crew/{comment_id}/\"\n",
    "\n",
    "    # Create a row for the CSV\n",
    "    row = {\n",
    "        \"text\": text,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"username\": username,\n",
    "        \"link\": link,\n",
    "        \"link_id\": link_id,\n",
    "        \"parent_id\": parent_id,\n",
    "        \"id\": comment_id,\n",
    "        \"subreddit_id\": subreddit_id,\n",
    "        \"moderation\": moderation,\n",
    "        \"year\": year,\n",
    "        \"concatenated_count\": concatenated_count,\n",
    "        \"complete_thread\": complete_thread,\n",
    "        \"gold_label\": gold_label,\n",
    "        \"generated_data\": True,\n",
    "    }\n",
    "\n",
    "    csv_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'hate_3_comments.csv' with 9861 rows generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# After generating all the rows in csv_data, shuffle them\n",
    "random.shuffle(csv_data)\n",
    "\n",
    "# Randomly sample 9861 rows\n",
    "sampled_data = random.sample(csv_data, 9861)\n",
    "\n",
    "# Define the column headers for the CSV\n",
    "csv_columns = csv_data[0].keys()\n",
    "\n",
    "# Writing the shuffled and sampled data to a CSV file\n",
    "csv_file = \"hate_3_comments.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sampled_data)\n",
    "\n",
    "print(f\"CSV file '{csv_file}' with 9861 rows generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
