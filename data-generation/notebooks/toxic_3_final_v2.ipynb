{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for Toxic 3 sentences (20 informal and mixed templates)\n",
    "toxic_3_templates = [\n",
    "    \"{individual_or_group} ah, youre such a {insult}. Just wait, Ill {threat} soon.\",\n",
    "    \"Eh {individual_or_group}, stop being such a {insult} before I {threat}.\",\n",
    "    \"{individual_or_group}, youre seriously the worst {insult}. I confirm {threat} you if this continues.\",\n",
    "    \"{individual_or_group} damn annoying lah, acting like a {insult}. Time to {threat}.\",\n",
    "    \"Oi {individual_or_group}, stop it lah. Youre such a {insult}. Soon Ill {threat}.\",\n",
    "    \"You think youre very smart, {individual_or_group}? Just a {insult}. I will {threat}.\",\n",
    "    \"{individual_or_group} confirm is the biggest {insult} around. Wait till I {threat}.\",\n",
    "    \"{individual_or_group}, seriously, what a joke. Youre a {insult}. I will {threat} soon.\",\n",
    "    \"Cannot tahan you anymore, {individual_or_group}. Acting like a {insult}? Time to {threat}.\",\n",
    "    \"Wah lau, {individual_or_group} is really a {insult}. Confirm kena {threat}.\",\n",
    "    \"Eh {individual_or_group}, enough with the {insult} act already, or Ill {threat}.\",\n",
    "    \"Honestly, {individual_or_group}, youre a proper {insult}. Soon Ill {threat}.\",\n",
    "    \"I cannot tahan {individual_or_group} anymore, such a {insult}. You better watch out, Ill {threat}.\",\n",
    "    \"{individual_or_group} always act like a {insult}. I swear I will {threat}.\",\n",
    "    \"Im really fed up with {individual_or_group}, such a {insult}. Time for me to {threat}.\",\n",
    "    \"Ive had enough of {individual_or_group}, always being a {insult}. Time to {threat}.\",\n",
    "    \"Its too much lah, {individual_or_group}. Being a {insult}? Ill make sure to {threat}.\",\n",
    "    \"The way {individual_or_group} acts, such a {insult}. Im about to {threat}.\",\n",
    "    \"{individual_or_group} better stop all this {insult} nonsense, or Ill {threat} soon.\",\n",
    "    \"Honestly, {individual_or_group}, dont test me. Being a {insult} will get you {threat}.\",\n",
    "]\n",
    "\n",
    "# Define potential individuals or groups (10 groups that are not part of sensitive groups)\n",
    "individual_or_group = [\n",
    "    \"that useless neighbor\",\n",
    "    \"your annoying colleague\",\n",
    "    \"the auntie who wont shut up\",\n",
    "    \"that reckless driver\",\n",
    "    \"the idiot from the gym\",\n",
    "    \"your control freak boss\",\n",
    "    \"that fake friend\",\n",
    "    \"the rude cashier\",\n",
    "    \"that clueless guy\",\n",
    "    \"your obnoxious ex\",\n",
    "]\n",
    "\n",
    "# Define potential insults (10 informal insults)\n",
    "insult = [\n",
    "    \"loser\",\n",
    "    \"idiot\",\n",
    "    \"hypocrite\",\n",
    "    \"failure\",\n",
    "    \"liar\",\n",
    "    \"crybaby\",\n",
    "    \"whiner\",\n",
    "    \"show-off\",\n",
    "    \"arrogant prick\",\n",
    "    \"wannabe\",\n",
    "]\n",
    "\n",
    "# Define potential threats (10 informal threats with Singaporean flavor)\n",
    "threat = [\n",
    "    \"make your life a living hell\",\n",
    "    \"ruin everything for you\",\n",
    "    \"report you to everyone\",\n",
    "    \"kill you\",\n",
    "    \"show everyone how useless you are\",\n",
    "    \"destroy your reputation\",\n",
    "    \"ruin your career\",\n",
    "    \"embarass you in front of everyone\",\n",
    "    \"make sure you regret this\",\n",
    "    \"show everyone how weak you are\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Cartesian product of all combinations\n",
    "\n",
    "\n",
    "def generate_deterministic_toxic_3_comments():\n",
    "    combinations = itertools.product(\n",
    "        toxic_3_templates, insult, individual_or_group, threat\n",
    "    )\n",
    "    comments = [\n",
    "        template.format(\n",
    "            insult=insult, individual_or_group=individual_or_group, threat=threat\n",
    "        )\n",
    "        for template, insult, individual_or_group, threat in combinations\n",
    "    ]\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique ID (e.g., comment id)\n",
    "\n",
    "\n",
    "def generate_unique_comment_id():\n",
    "    return \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz0123456789\", k=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique link ID (e.g., \"t3_\" followed by 6 characters)\n",
    "\n",
    "\n",
    "def generate_unique_link_id():\n",
    "    return \"t3_\" + \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz0123456789\", k=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random timestamp (date and time) in 2023\n",
    "\n",
    "\n",
    "def generate_random_timestamp(year=2023):\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31)\n",
    "    random_date = start_date + timedelta(\n",
    "        days=random.randint(0, (end_date - start_date).days)\n",
    "    )\n",
    "\n",
    "    # Generate random hours, minutes, and seconds\n",
    "    random_time = timedelta(\n",
    "        hours=random.randint(0, 23),\n",
    "        minutes=random.randint(0, 59),\n",
    "        seconds=random.randint(0, 59),\n",
    "    )\n",
    "\n",
    "    # Combine the random date with the random time\n",
    "    full_random_datetime = random_date + random_time\n",
    "\n",
    "    # Return in the desired format\n",
    "    return full_random_datetime.strftime(\"%m/%d/%Y %I:%M:%S %p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random 6-letter username (alphabets only)\n",
    "\n",
    "\n",
    "def generate_username():\n",
    "    return \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz\", k=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5000 deterministic comments\n",
    "toxic_3_data = generate_deterministic_toxic_3_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file columns\n",
    "csv_columns = [\n",
    "    \"text\",\n",
    "    \"timestamp\",\n",
    "    \"username\",\n",
    "    \"link\",\n",
    "    \"link_id\",\n",
    "    \"parent_id\",\n",
    "    \"id\",\n",
    "    \"subreddit_id\",\n",
    "    \"moderation\",\n",
    "    \"year\",\n",
    "    \"word_count\",\n",
    "    \"Sensitive Group\",\n",
    "    \"Classification\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant values\n",
    "subreddit_id = \"t5_2qh8c\"\n",
    "moderation = \"{'controversiality': 0, 'collapsed_reason_code': None, 'collapsed': False, 'collapsed_reason': None}\"\n",
    "year = 2023  # Keeping year as an integer\n",
    "classification = \"Toxic 3\"  # Change from gold_label to Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare rows for CSV\n",
    "csv_data = []\n",
    "for i in range(20000):\n",
    "    text = toxic_3_data[i]  # Ensure this is your list of comments for Toxic 3\n",
    "    timestamp = generate_random_timestamp()\n",
    "    username = generate_username()\n",
    "    link_id = generate_unique_link_id()\n",
    "    parent_id = link_id  # Same within each row\n",
    "    comment_id = generate_unique_comment_id()  # Unique ID for each comment\n",
    "    link = f\"/r/singapore/comments/13c3mt8/Strict_appearance_and_grooming_standards_for_Singapore_Airlines_cabin_crew/{comment_id}/\"\n",
    "\n",
    "    # Create a row for the CSV with columns matching balanced_data\n",
    "    row = {\n",
    "        \"text\": text,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"username\": username,\n",
    "        \"link\": link,\n",
    "        \"link_id\": link_id,\n",
    "        \"parent_id\": parent_id,\n",
    "        \"id\": comment_id,\n",
    "        \"subreddit_id\": subreddit_id,\n",
    "        \"moderation\": moderation,\n",
    "        \"year\": year,\n",
    "        \"word_count\": len(text.split()),  # Calculate word count from the text\n",
    "        \"Sensitive Group\": None,  # Set this appropriately if needed\n",
    "        \"Classification\": classification,  # Set the classification directly\n",
    "    }\n",
    "\n",
    "    csv_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'toxic_3_comments.csv' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# After generating all the rows in csv_data, shuffle them\n",
    "random.shuffle(csv_data)\n",
    "selected_data = csv_data[:14568]\n",
    "\n",
    "\n",
    "# Writing the shuffled data to a CSV file\n",
    "csv_file = \"toxic_3_comments.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(selected_data)\n",
    "\n",
    "print(f\"CSV file '{csv_file}' generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
