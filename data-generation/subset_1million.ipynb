{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4381725, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    r\"/Users/richmondsin/Desktop/DSA4264/DSA4264-Detoxify/kedro-data/data/03_primary/clean_gt_texts_data.csv/2024-10-24T05.15.04.503Z/clean_gt_texts_data.csv\"\n",
    ")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868364     Ngl, I'd be worried. Who gives out phone numbe...\n",
      "1490409    Circuit breaker is also a widely used word in ...\n",
      "2921161    Private out lol. Gov job nowadays also all giv...\n",
      "2674987    I studied in New Zealand for 8 years amp was t...\n",
      "4056624    Singapores steepest drop in birth rate was fro...\n",
      "4080688    Heres ten cents, my two cents are free Guess a...\n",
      "2559174    is it really ur leave day if u aren't getting ...\n",
      "1319148              Can definitely sleep well at night nao!\n",
      "3099057                      They claim Bukit Batok province\n",
      "3691036    IT'S IKEA'S STRANDMON! i'm sorry idk why i sai...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sample_texts = data[\"text\"].sample(n=10, random_state=42)  # Get random samples\n",
    "print(sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'timestamp', 'username', 'link', 'link_id', 'parent_id', 'id', 'subreddit_id', 'moderation', 'year']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique word counts: 1641\n",
      "word_count\n",
      "1.0      126673\n",
      "2.0      130028\n",
      "3.0      152811\n",
      "4.0      166991\n",
      "5.0      173137\n",
      "          ...  \n",
      "96.0       4571\n",
      "97.0       4332\n",
      "98.0       4195\n",
      "99.0       4029\n",
      "100.0      4096\n",
      "Name: count, Length: 100, dtype: int64\n",
      "word_count\n",
      "1589.0    2\n",
      "1590.0    1\n",
      "1591.0    2\n",
      "1592.0    2\n",
      "1593.0    1\n",
      "         ..\n",
      "1840.0    1\n",
      "1842.0    1\n",
      "1864.0    1\n",
      "1868.0    1\n",
      "1872.0    1\n",
      "Name: count, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the word count for each text entry\n",
    "data[\"word_count\"] = data[\"text\"].str.split(\" \").str.len()\n",
    "\n",
    "# Count the occurrences of each unique word count\n",
    "word_count_counts = data[\"word_count\"].value_counts().sort_index()\n",
    "\n",
    "# Display the number of unique word counts\n",
    "num_unique_word_counts = word_count_counts.count()\n",
    "print(f\"Number of unique word counts: {num_unique_word_counts}\")\n",
    "\n",
    "# Display more results\n",
    "word_count_counts_display = word_count_counts[word_count_counts > 0]\n",
    "print(\n",
    "    word_count_counts_display.head(100)\n",
    ")  # Display the first 100 word counts for a quick overview\n",
    "print(\n",
    "    word_count_counts_display.tail(100)\n",
    ")  # Display the last 100 word counts for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean word count: 32.32\n",
      "Median word count: 16.00\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and median word count\n",
    "mean_word_count = data[\"word_count\"].mean()\n",
    "median_word_count = data[\"word_count\"].median()\n",
    "\n",
    "print(f\"Mean word count: {mean_word_count:.2f}\")\n",
    "print(f\"Median word count: {median_word_count:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with more than 5 words and 50 words or less: 3117245\n"
     ]
    }
   ],
   "source": [
    "# Count entries with more than 5 words and 80 words or less\n",
    "count_entries = data[(data[\"word_count\"] >= 5) & (data[\"word_count\"] <= 50)].shape[0]\n",
    "\n",
    "print(f\"Number of entries with more than 5 words and 50 words or less: {count_entries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           text\n",
      "1041425               You broke up recently too\n",
      "2341273              How to reschedule Help pls\n",
      "2075990                         Why M and not P\n",
      "2413377                 Knn 14 minimum is crazy\n",
      "642730                 I smell a lawsuit coming\n",
      "1652877             Yeah that's the plus point!\n",
      "3395226          Thank you for the explanation.\n",
      "3030423                Or cher in the classroom\n",
      "2667886             Eating in moderation, is ok\n",
      "3866161  aka dishonorable discharge. SAY SORRY!\n"
     ]
    }
   ],
   "source": [
    "# one_char_texts = data[data['text'].str.len() == 5]\n",
    "five_words = data[data[\"word_count\"] == 5]\n",
    "# Get 10 examples\n",
    "examples = (\n",
    "    five_words.sample(n=10, random_state=62) if len(five_words) >= 10 else five_words\n",
    ")\n",
    "\n",
    "# Display the examples\n",
    "print(examples[[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle whole dataset\n",
    "shuffled_data = data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampling complete. Files saved as 'text_subset_part_1.csv' to 'text_subset_part_5.csv' and 'other_than_1million.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Filter for entries with at least 5 words and less than or equal to 50 words\n",
    "filtered_data = shuffled_data[\n",
    "    (shuffled_data[\"word_count\"] >= 5) & (shuffled_data[\"word_count\"] <= 50)\n",
    "]\n",
    "\n",
    "# Save the filtered out data (those not meeting the word count criteria)\n",
    "filtered_out_data = shuffled_data[~shuffled_data.index.isin(filtered_data.index)]\n",
    "\n",
    "# Take a subsample of 1 million rows\n",
    "subset_size = min(1000000, len(filtered_data))\n",
    "subset = filtered_data.iloc[:subset_size]\n",
    "\n",
    "# Save the remaining non-filtered data\n",
    "remaining_data = filtered_data.iloc[subset_size:]\n",
    "\n",
    "# Combine filtered out data and remaining data\n",
    "combined_data = pd.concat([filtered_out_data, remaining_data], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "combined_data.to_csv(\"other_than_1million.csv\", index=False)\n",
    "\n",
    "# Split the subset into 5 different CSV files\n",
    "num_files = 5\n",
    "rows_per_file = len(subset) // num_files\n",
    "\n",
    "for i in range(num_files):\n",
    "    start_idx = i * rows_per_file\n",
    "    end_idx = (\n",
    "        (i + 1) * rows_per_file if i < num_files - 1 else len(subset)\n",
    "    )  # Handle the last file\n",
    "    subset.iloc[start_idx:end_idx].to_csv(\n",
    "        f\"1million_subset_part_{i + 1}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"Subsampling complete. Files saved as 'text_subset_part_1.csv' to 'text_subset_part_5.csv' and 'other_than_1million.csv'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3381725, 11)\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
